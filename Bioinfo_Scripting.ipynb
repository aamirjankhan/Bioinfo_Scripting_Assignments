{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "{'buys_computer': ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no'], 'age': ['31-40', '>40', '>40', '31-40', '<=30', '>40', '<=30', '31-40', '31-40', '<=30', '<=30', '>40', '<=30', '>40'], 'income': ['high', 'medium', 'low', 'low', 'low', 'medium', 'medium', 'medium', 'high', 'high', 'high', 'medium', 'medium', 'low'], 'student': ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes'], 'credit_rating': ['fair', 'fair', 'fair', 'excellent', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'excellent']}\n",
      "Column buys_computer: yes = 9; no = 5\n",
      "Column age: <=30 = 5; 31-40 = 4; >40 = 5\n",
      "Column income: low = 4; high = 4; medium = 6\n",
      "Column student: yes = 7; no = 7\n",
      "Column credit_rating: excellent = 6; fair = 8\n"
     ]
    }
   ],
   "source": [
    "file=open(\"ExampleData_29oct2019.txt\",\"r\",encoding=\"utf8\").read().split(\"\\n\")\n",
    "file1=[]\n",
    "for i in range(len(file)):\n",
    "    file1.append(file[i].split(\"\\t\"))\n",
    "count=0\n",
    "for data in file1:\n",
    "    count+=1\n",
    "    if data is ['']:\n",
    "        break\n",
    "print(count)\n",
    "dict1={}\n",
    "lst=[]\n",
    "for j in range(5):\n",
    "    for k in range(1,15):\n",
    "        strr=file1[0][j]\n",
    "        lst.append(file1[k][j])\n",
    "    dict1.update({strr:lst})\n",
    "    lst=[]\n",
    "print(dict1)\n",
    "def func1(dict1):\n",
    "    for i,j in dict1.items():\n",
    "        set1=set(j)\n",
    "        lst1=list(set1)\n",
    "        if len(lst1)==2:\n",
    "            print(\"Column \"+i+\": \"+lst1[0]+\" = \"+str(j.count(lst1[0]))+\"; \"+lst1[1]+\" = \"+str(j.count(lst1[1])))\n",
    "        elif len(lst1)==3:\n",
    "            print(\"Column \"+i+\": \"+lst1[0]+\" = \"+str(j.count(lst1[0]))+\"; \"+lst1[1]+\" = \"+str(j.count(lst1[1]))+\"; \"+lst1[2]+\" = \"+str(j.count(lst1[2])))\n",
    "\n",
    "func1(dict1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write a program:\n",
    "That takes two inputs from a user at run time: (a) a DNA sequence;\n",
    "and (b) an action to perform. The action will be one of these:\n",
    "reverse, complement, reverse-complement, RNA, GC% percentage,\n",
    "CG-skew or content, and location of start and stop codons if present.\n",
    "Each action should be a separate function in the code. Print a message with\n",
    "“invalid choice” if the user selects an action other than not implemented\n",
    "in the program.\n",
    "Also, program should print an “invalid sequence” message if the provided\n",
    "input DNA sequence contains characters other than A, T, C, and ‘G’.\n",
    "Program should be able to take DNA input in both upper and lower case\n",
    "letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please entera valid nucleotide sequence: TTCACCCCGCCAGGGTCACCCTATACGTTCATATACATGATGGGCCGTAGCTTCACTCCACGCACTATCTTAGTTATGCATCAAGGAGATCATGAATATTCAAATTCCAATTAG\n",
      "            press 1 to reverse your DNA\n",
      "            press 2 to find compliment of your DNA\n",
      "            press 3 to find reverse compliment of your DNA\n",
      "            press 4 to find GC content\n",
      "            press 5 to convert your DNA into RNA\n",
      "            press 6 to find the start and stop codon positions\n",
      "            press 7 to find gc skew or content6\n",
      "['ttc', 'acc', 'ccg', 'cca', 'ggg', 'tca', 'ccc', 'tat', 'acg', 'ttc', 'ata', 'tac', 'atg', 'atg', 'ggc', 'cgt', 'agc', 'ttc', 'act', 'cca', 'cgc', 'act', 'atc', 'tta', 'gtt', 'atg', 'cat', 'caa', 'gga', 'gat', 'cat', 'gaa', 'tat', 'tca', 'aat', 'tcc', 'aat', 'tag']\n",
      "start codon start site is: 75 and stop codon start site is: 111\n"
     ]
    }
   ],
   "source": [
    "dna=input(\"please entera valid nucleotide sequence: \")\n",
    "dna=dna.lower() if dna.isupper() else dna\n",
    "'''\n",
    "def func1(dna):\n",
    "    print('invalid input!!!')\n",
    "    new_dna=input('please enter a valid dna sequence: ')\n",
    "    return new_dna \n",
    "for base in list(dna):\n",
    "    if base != 'a' or base != 't' or base != 'c' or base != 'g':\n",
    "        dna=func1(dna)\n",
    "        break\n",
    "'''\n",
    "option=input('\\\n",
    "            press 1 to reverse your DNA\\n\\\n",
    "            press 2 to find compliment of your DNA\\n\\\n",
    "            press 3 to find reverse compliment of your DNA\\n\\\n",
    "            press 4 to find GC content\\n\\\n",
    "            press 5 to convert your DNA into RNA\\n\\\n",
    "            press 6 to find the start and stop codon positions\\n\\\n",
    "            press 7 to find gc skew or content')\n",
    "def func2(dna):\n",
    "    return dna[::-1]\n",
    "def func3(dna):\n",
    "    comp=list(dna)\n",
    "    for i in range(len(comp)):\n",
    "        if comp[i] is 'a':\n",
    "            comp[i]='t'\n",
    "        elif comp[i] is 't':\n",
    "            comp[i]='a'\n",
    "        elif comp[i] is 'c':\n",
    "            comp[i]='g'\n",
    "        elif comp[i] is 'g':\n",
    "            comp[i]='c'\n",
    "    return \"\".join(comp)\n",
    "def func4(dna):\n",
    "    comp=list(dna[::-1])\n",
    "    for i in range(len(comp)):\n",
    "        if comp[i] is 'a':\n",
    "            comp[i]='t'\n",
    "        elif comp[i] is 't':\n",
    "            comp[i]='a'\n",
    "        elif comp[i] is 'c':\n",
    "            comp[i]='g'\n",
    "        elif comp[i] is 'g':\n",
    "            comp[i]='c'\n",
    "    return \"\".join(comp)\n",
    "def func5(dna):\n",
    "    length=len(dna)\n",
    "    gc=0\n",
    "    dna1=list(dna)\n",
    "    for i in range(length):\n",
    "        if dna1[i] is 'c' or dna1[i] is 'g':\n",
    "            gc+=1\n",
    "    return (gc/length)*100\n",
    "def func6(dna):\n",
    "    dna=list(dna)\n",
    "    codons=[]\n",
    "    var1=0\n",
    "    var2=3\n",
    "    for i in range(len(dna)//3):\n",
    "        codons.append(\"\".join(dna[var1:var2]))\n",
    "        var1+=3\n",
    "        var2+=3\n",
    "    print(codons)\n",
    "    start=0\n",
    "    stop=0\n",
    "    for i in range(len(codons)):\n",
    "        if codons[i] == 'atg':\n",
    "            start=i\n",
    "        elif codons[i] == 'taa' or codons[i] == 'tga' or codons[i] == 'tag':\n",
    "            stop=i\n",
    "    return start,stop\n",
    "def func7(dna):\n",
    "    dna=list(dna)\n",
    "    for i in range(len(dna)):\n",
    "        if dna[i] is 't':\n",
    "            dna[i]='u'\n",
    "    return \"\".join(dna)\n",
    "def func8(dna):\n",
    "    dna=list(dna)\n",
    "    g=0\n",
    "    c=0\n",
    "    for i in range(len(dna)):\n",
    "        if dna[i] is 'g':\n",
    "            g+=1\n",
    "        elif dna[i] is 'c':\n",
    "            c+=1\n",
    "    if g == c:\n",
    "        return 0\n",
    "    else:\n",
    "        return (c-g)/(c+g)\n",
    "if option is '1':\n",
    "    print(func2(dna))\n",
    "elif option is '2':\n",
    "    print(func3(dna))\n",
    "elif option is '3':\n",
    "    print(func4(dna))\n",
    "elif option is '4':\n",
    "    print('gc content is: {}'.format(func5(dna)))\n",
    "elif option is '6':\n",
    "    start,stop=func6(dna)\n",
    "    print('start codon start site is: {} and stop codon start site is: {}'.format(start*3,stop*3))\n",
    "elif option is '5':\n",
    "    print(func7(dna))\n",
    "elif option is '7':\n",
    "    print('gc skew or content is : {}'.format(func8(dna)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttcacctatgaantggactgtccccaaagaagtanggacccactaatgcagnatcctgtg\n",
      "please enter a valid nucleotide sequence: ttcacctatgaantggactgtccccaaagaagtanggacccactaatgcagnatcctgtg\n",
      "n changed to a\n",
      "non nucleotide occurance is on index: 12\n",
      "n changed to g\n",
      "non nucleotide occurance is on index: 34\n",
      "n changed to g\n",
      "non nucleotide occurance is on index: 51\n",
      "ttcacctatgaaatggactgtccccaaagaagtagggacccactaatgcaggatcctgtg\n",
      "Sequence_ID\t\tlength\tStart\tEnd\tPercentage identity\n",
      "SRR5099741.41377\t64\t55\t64\t\t100.0\n",
      "Sequence_ID\t\tlength\tStart\tEnd\tPercentage identity\n",
      "SRR5099741.70758\t101\t92\t101\t\t100.0\n",
      "Sequence_ID\t\tlength\tStart\tEnd\tPercentage identity\n",
      "SRR5099741.95223\t99\t91\t99\t\t100.0\n",
      "Sequence_ID\t\tlength\tStart\tEnd\tPercentage identity\n",
      "SRR5099741.21894\t102\t89\t102\t\t92.3076923076923\n",
      "Sequence_ID\t\tlength\tStart\tEnd\tPercentage identity\n",
      "SRR5099741.21983\t101\t89\t101\t\t83.33333333333334\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import random #importing random method to choose random elements from a list of A,T,C,G\n",
    "import re\n",
    "nucleotides=['a','t','c','g'] #list of nucleotides\n",
    "print(\"ttcacctatgaantggactgtccccaaagaagtanggacccactaatgcagnatcctgtg\")\n",
    "strr=list(input('please enter a valid nucleotide sequence: ')) #taking input from the user and converting it to list\n",
    "n=0 #flag variable\n",
    "while(n!=len(strr)): #while loop \n",
    "    if(strr[n]!='a' and strr[n]!='t' and strr[n]!='c' and strr[n]!='g'): #if a residue is other then A G C T\n",
    "        neut=random.choice(nucleotides) #replacing nucleotides\n",
    "        print(strr[n]+' changed to '+neut) \n",
    "        strr[n]=neut\n",
    "        print('non nucleotide occurance is on index: '+str(n)) #displaying the non nucleotide occurance\n",
    "    n+=1 #additive operator\n",
    "print(''.join(strr)) #converting it back to the string\n",
    "frr=open(\"sequences.txt\",\"r\") #opening the file containing the sequences\n",
    "line=frr.readline()\n",
    "sequences,sequence1,sequence_rev,ids,poly_A,lenght,start,end,score=[],[],[],[],[],[],[],[],[]\n",
    "#lists of id's, poly A tails, poly A start, poly A end, length of the sequences, and a score list\n",
    "while(line):\n",
    "    sequences.append(line.rstrip()) #appending sequences for further operations\n",
    "    line=frr.readline()\n",
    "while \"\" in sequences:\n",
    "        sequences.remove(\"\") #removing extra empty indexes from the list\n",
    "\n",
    "def func1(lst,lst1): #function to get the sequences and appending to another list\n",
    "    for i in range(len(lst)):\n",
    "        if \">\" not in lst[i]:\n",
    "            lst1.append(lst[i])\n",
    "func1(sequences,sequence1)\n",
    "\n",
    "def func2(lst,lst1): #function to reverse the sequences for our ease, inorder to get the poly A tail \n",
    "    for i in range(len(lst)):\n",
    "        seq=lst[i]\n",
    "        lst1.append(seq[::-1]) #appending into an other list for further ease\n",
    "func2(sequence1,sequence_rev)\n",
    "\n",
    "def func3(lst,lst1,lst2): #function to retreive the sequence id's\n",
    "    pattern=re.compile(r\"\\w+\\.\\d+\") #pattern\n",
    "    for i in range(len(lst)):\n",
    "        match=pattern.findall(lst[i])\n",
    "        lst1.extend(match)\n",
    "    for i in range(len(lst)):\n",
    "       if not \">\" in lst[i]:\n",
    "           lst2.append(len(lst[i]))\n",
    "    while [] in lst1:\n",
    "        lst1.remove([]) #removing empty indexes of a list\n",
    "func3(sequences,ids,lenght)\n",
    "\n",
    "def func4(lst,lst1,lst2,start,end): #function to get the poly A tail, its start, its end, whilst allowing one mismatch at a time\n",
    "    pattern=re.compile(r\"^[A]{3,10}[CTG]{0,1}[A]+[CTG]{0,1}[A]+\") #pattern for allowing one mismatch at a time\n",
    "    for i in range(len(lst)):\n",
    "        match=pattern.findall(lst[i])\n",
    "        lst1.extend(match)\n",
    "    while [] in lst1:\n",
    "        lst1.remove([])\n",
    "    for j in range(len(lst)):\n",
    "        start.append(len(lst[j])-len(lst1[j]))\n",
    "        end.append(len(lst[j]))\n",
    "\n",
    "    \n",
    "def func5(lst1,lst2): #function to get the percentage identity of the poly A tail\n",
    "    for i in range(len(lst1)):\n",
    "        seq=lst1[i]\n",
    "        match=0\n",
    "        mismatch=0\n",
    "        for s in seq:\n",
    "            if s is \"A\":\n",
    "                match+=1 #counting the number of mismatches and matches\n",
    "            else:\n",
    "                mismatch+=1\n",
    "        lst2.append((match/(match+mismatch))*100)  #applying the formula         \n",
    "func4(sequence_rev,poly_A,sequences,start,end)\n",
    "\n",
    "func5(poly_A,score)\n",
    "\n",
    "\n",
    "def func6(lst1,lst2,lst3,lst4,lst5): #function to display all the results in the given format by sir Nadeem\n",
    "    for i in range(5):\n",
    "        print(\"Sequence_ID\\t\\tlength\\tStart\\tEnd\\tPercentage identity\")\n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t\\t{}\".format(lst1[i],lst2[i],lst3[i],lst4[i],lst5[i]))\n",
    "print(func6(ids,lenght,start,end,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the diatance between ATCCAGCT and ATCCAGCT is 0\n",
      "the diatance between ATCCAGCT and GGGCAACT is 4\n",
      "the diatance between ATCCAGCT and ATGGATCT is 3\n",
      "the diatance between ATCCAGCT and AAGCAACC is 4\n",
      "the diatance between ATCCAGCT and TTGGAACT is 4\n",
      "the diatance between ATCCAGCT and ATGCCATT is 4\n",
      "the diatance between ATCCAGCT and ATGGCACT is 4\n",
      "the diatance between GGGCAACT and ATCCAGCT is 4\n",
      "the diatance between GGGCAACT and GGGCAACT is 0\n",
      "the diatance between GGGCAACT and ATGGATCT is 4\n",
      "the diatance between GGGCAACT and AAGCAACC is 3\n",
      "the diatance between GGGCAACT and TTGGAACT is 3\n",
      "the diatance between GGGCAACT and ATGCCATT is 4\n",
      "the diatance between GGGCAACT and ATGGCACT is 4\n",
      "the diatance between ATGGATCT and ATCCAGCT is 3\n",
      "the diatance between ATGGATCT and GGGCAACT is 4\n",
      "the diatance between ATGGATCT and ATGGATCT is 0\n",
      "the diatance between ATGGATCT and AAGCAACC is 4\n",
      "the diatance between ATGGATCT and TTGGAACT is 2\n",
      "the diatance between ATGGATCT and ATGCCATT is 4\n",
      "the diatance between ATGGATCT and ATGGCACT is 2\n",
      "the diatance between AAGCAACC and ATCCAGCT is 4\n",
      "the diatance between AAGCAACC and GGGCAACT is 3\n",
      "the diatance between AAGCAACC and ATGGATCT is 4\n",
      "the diatance between AAGCAACC and AAGCAACC is 0\n",
      "the diatance between AAGCAACC and TTGGAACT is 4\n",
      "the diatance between AAGCAACC and ATGCCATT is 4\n",
      "the diatance between AAGCAACC and ATGGCACT is 4\n",
      "the diatance between TTGGAACT and ATCCAGCT is 4\n",
      "the diatance between TTGGAACT and GGGCAACT is 3\n",
      "the diatance between TTGGAACT and ATGGATCT is 2\n",
      "the diatance between TTGGAACT and AAGCAACC is 4\n",
      "the diatance between TTGGAACT and TTGGAACT is 0\n",
      "the diatance between TTGGAACT and ATGCCATT is 4\n",
      "the diatance between TTGGAACT and ATGGCACT is 2\n",
      "the diatance between ATGCCATT and ATCCAGCT is 4\n",
      "the diatance between ATGCCATT and GGGCAACT is 4\n",
      "the diatance between ATGCCATT and ATGGATCT is 4\n",
      "the diatance between ATGCCATT and AAGCAACC is 4\n",
      "the diatance between ATGCCATT and TTGGAACT is 4\n",
      "the diatance between ATGCCATT and ATGCCATT is 0\n",
      "the diatance between ATGCCATT and ATGGCACT is 2\n",
      "the diatance between ATGGCACT and ATCCAGCT is 4\n",
      "the diatance between ATGGCACT and GGGCAACT is 4\n",
      "the diatance between ATGGCACT and ATGGATCT is 2\n",
      "the diatance between ATGGCACT and AAGCAACC is 4\n",
      "the diatance between ATGGCACT and TTGGAACT is 2\n",
      "the diatance between ATGGCACT and ATGCCATT is 2\n",
      "the diatance between ATGGCACT and ATGGCACT is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nhamming distance:\\n    the meaure of dissimilarity between two sequences\\n    i.e. the number of positions at which a residue needs to be changed\\n    number of subsitutions need to transform one string into another\\n    ATCGGTAGT\\n      | | ||              \\n    ATGGTTCCT\\n    hence the hamming distance is 4\\nlevenshtein distance:\\n    levenshtein diatance is also a method calculate dissimilarity between two sequences but is more advanced as compared with hamming\\n    distance\\n    it inserts gaps and then modify the sequences and then compare two strings to find the distance\\n    consider these two sequences\\n    ATCGGATGGG\\n    ||| |||  |            \\n    TCGGTTGGGAC\\n    the hamming distance would be 7 but is not as much accurate\\n    if we insert gaps, then\\n    ATCGGATGGG--\\n    |    |    ||             \\n    -TCGGTTGGGAC\\n    hence after gap insertion the levenshtein distance would be only 4\\n    \\n    \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences1 = [\"ATCCAGCT\", \"GGGCAACT\",\"ATGGATCT\", \"AAGCAACC\",\"TTGGAACT\", \"ATGCCATT\", \"ATGGCACT\"]\n",
    "sequences2 = [\"ATCCAGCT\", \"GGGCAACT\",\"ATGGATCT\", \"AAGCAACC\",\"TTGGAACT\", \"ATGCCATT\", \"ATGGCACT\"] #sequences to create dimers and then to compare them and finding the hamming distance\n",
    "combinations=[]\n",
    "score=[]\n",
    "\n",
    "def func1(seq1,seq2,score): #function to calculate the distance between two sequences and appending the score into an other list\n",
    "    seqa=list(seq1) #converting into list, indivisual indexes will be converted of the sequences1 or sequences2 lists\n",
    "    seqb=list(seq2)\n",
    "    mis_match=0 #distance represented by mismatch and will be stored in the mismatch variable\n",
    "    for i in range(8):\n",
    "        if seqa[i]!=seqb[i]:\n",
    "            mis_match+=1\n",
    "    score.append(mis_match) #appending the score into the score list\n",
    "    return mis_match #returning the mismatch value\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        combinations.append(sequences1[i]) #each indivisual indexes will be returned to the function 1 and then the distances will be calculated\n",
    "        combinations.append(sequences2[j])\n",
    "        x=func1(sequences1[i],sequences2[j],score)\n",
    "        data=\"the diatance between {} and {} is {}\".format(sequences1[i],sequences2[j],x) #displaying in the form as asked by sir nadeem\n",
    "        print(data)\n",
    "        \n",
    "# hamming and levenshtein distances explained with the help of an example\n",
    "\"\"\"\n",
    "hamming distance:\n",
    "    the meaure of dissimilarity between two sequences\n",
    "    i.e. the number of positions at which a residue needs to be changed\n",
    "    number of subsitutions need to transform one string into another\n",
    "    ATCGGTAGT\n",
    "      | | ||              \n",
    "    ATGGTTCCT\n",
    "    hence the hamming distance is 4\n",
    "levenshtein distance:\n",
    "    levenshtein diatance is also a method calculate dissimilarity between two sequences but is more advanced as compared with hamming\n",
    "    distance\n",
    "    it inserts gaps and then modify the sequences and then compare two strings to find the distance\n",
    "    consider these two sequences\n",
    "    ATCGGATGGG\n",
    "    ||| |||  |            \n",
    "    TCGGTTGGGAC\n",
    "    the hamming distance would be 7 but is not as much accurate\n",
    "    if we insert gaps, then\n",
    "    ATCGGATGGG--\n",
    "    |    |    ||             \n",
    "    -TCGGTTGGGAC\n",
    "    hence after gap insertion the levenshtein distance would be only 4\n",
    "    \n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar sequences in both human and mouse are: 91\n",
      "sequences similar in both human and mouse are: \n",
      "['CYTC_', 'GHRL_', 'PCSK1_', 'SCG3_', 'SCG2_', 'SCG1_', 'NEUT_', 'OSTN_', 'PACA_', 'CMGA_', 'TIP39_', 'SECR_', 'OREX_', 'EDN1_', 'EDN3_', 'EDN2_', 'PENK_', 'ADM2_', 'CCKN_', 'ADML_', 'KISS1_', 'UTS2B_', 'GALP_', 'PDYN_', 'GIP_', 'REL3_', 'SMS_', 'REL1_', 'CART_', 'CORT_', 'NMU_', 'GALA_', 'PNOC_', 'PAHO_', 'NUCB2_', 'PYY_', 'SPXN_', 'NMS_', 'APEL_', 'MCH_', 'NPB_', 'NPY_', 'OX26_', 'NPW_', 'NEU1_', 'NEU2_', 'UTS2_', 'PDGFA_', 'COLI_', 'TKNK_', 'RFRP_', 'CRF_', 'UCN2_', 'SLIB_', 'UCN1_', 'GAST_', 'AUGN_', 'ANFC_', 'ANFB_', 'TKN4_', 'INSL5_', 'INSL6_', 'VIP_', 'INSL3_', 'GLUC_', 'PTHY_', 'NMB_', 'PTHR_', 'GON1_', 'IGF2_', 'TRH_', 'PDGFB_', 'CALCA1_', 'PDGFD_', 'GRP_', 'PRRP_', 'VGF_', 'IAPP_', 'VEGFD_', 'HEPC_', 'VEGFC_', 'NPFF_', 'UCN3_', 'ANF_', 'TOR2X_', 'PROK2_', 'RES18_', 'TKN1_', 'NPS_', 'CALCA_', 'CALCB_']\n",
      "sequences present in human dictionary are: \n",
      "['ADM5_', 'PPY2_', 'IGF1a_', 'IGF1b_', 'IGF1c_', 'GON2_', 'MCHL1_', 'MOTI_', 'MCHL2_', 'INSL4_', 'REL2_', 'INS_']\n",
      "sequences present only in human dictionary are: 12\n",
      "sequences present in mouse dictionary are: \n",
      "['HEPC2_', 'IGF1_', 'INS1_', 'INS2_']\n",
      "sequences present only in human dictionary are: 4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "fr1=open(\"human.txt\",\"r\") #opening the human.txt file\n",
    "fr2=open(\"mouse.txt\",\"r\") #opening the mouse.txt file\n",
    "i,j=0,0 #itretable variables\n",
    "human,mouse={},{} #human and mouse dictionaries, keys will be the id whereas the values will be the sequences \n",
    "lst=[]\n",
    "lst1=[]\n",
    "only_human,only_mouse=[],[]\n",
    "def func1(frr,i,dictt): #function to find the keys and the values and returning them into the dictionaries \n",
    "    pattern=re.compile(r\"[^>]\\w+\\_\\w+\") #pattern to start with > then any alpha numeric character then an underscore followed by an alpha numeric character\n",
    "    line=frr.readline() #reading individual lines of the file\n",
    "    while(line): #reading the file line by line\n",
    "        if \">\" in line: #> will depict the start of the sequence identities\n",
    "            match=pattern.findall(line) #finding the pattern in the line and saving it into a match list\n",
    "            match1=match[0]\n",
    "            i+=1\n",
    "        dictt.update({match1:line.rstrip()}) #updating the dictionaries, match will be the sequence id and line will be the sequence\n",
    "        line=frr.readline() #reading the next line and then storing it into the line again and the while loop will run until line variable will be empty\n",
    "    \n",
    "    return dictt #returning the dictionary \n",
    "similar=[] #sequences similar in both humans and mouse\n",
    "present_human=[] #sequences present only in the human values of the dictionaries\n",
    "present_mouse=[] #sequences present only in the mouse values of the dictionaries\n",
    "human=func1(fr1,i,human)\n",
    "mouse=func1(fr2,j,mouse)\n",
    "human_keys=list(human.keys()) #storing keys of human in the list\n",
    "human_values=list(human.values()) #storing the values of human in the list\n",
    "mouse_keys=list(mouse.keys()) #storing keys of mouse into a list\n",
    "mouse_values=list(mouse.values()) #storing mouse values into a list\n",
    "human_keys_update=[]\n",
    "mouse_keys_update=[]\n",
    "def func3(lst,lst1): #function to find the value before underscore from the keys\n",
    "    pattern=re.compile(r\"[^>]\\w+[&\\_]\")\n",
    "    for i in range(len(lst)):\n",
    "        match=pattern.findall(lst[i])\n",
    "        match1=match[0]\n",
    "        lst1.append(match1)\n",
    "func3(human_keys,human_keys_update)\n",
    "func3(mouse_keys,mouse_keys_update)\n",
    "\n",
    "\n",
    "def func5(lst1,lst2,lst3): #function to find dissimilar sequences \n",
    "    for name1 in lst2:\n",
    "        if not name1 in lst1:\n",
    "            lst3.append(name1)\n",
    "def func4(lst1,lst2,lst3,lst4): #function to find the similar sequences\n",
    "    for name in lst1:\n",
    "        if name in lst2:\n",
    "           lst3.append(name)\n",
    "        elif name not in lst2: #finding the dissimilar sequences in either mouse or humans\n",
    "            lst4.append(name)\n",
    "    \n",
    "\n",
    "func4(human_keys_update,mouse_keys_update,similar,present_human)\n",
    "func5(human_keys_update,mouse_keys_update,present_mouse)\n",
    "print(\"similar sequences in both human and mouse are: {}\".format(len(similar)))\n",
    "print(\"sequences similar in both human and mouse are: \\n{}\".format(similar))\n",
    "print(\"sequences present in human dictionary are: \\n{}\".format(present_human))\n",
    "print(\"sequences present only in human dictionary are: {}\".format(len(present_human)))\n",
    "print(\"sequences present in mouse dictionary are: \\n{}\".format(present_mouse))\n",
    "print(\"sequences present only in human dictionary are: {}\".format(len(present_mouse)))\n",
    "# the code below was an approach to compare sequences but the approach was wrong hence the code is commented\n",
    "'''\n",
    "def func2(strr1,strr2,lst1):\n",
    "    glob=False\n",
    "    for sequence in strr1:\n",
    "        if not sequence in strr2:\n",
    "            glob=False\n",
    "        else:\n",
    "            glob=True\n",
    "        \n",
    "    if glob == True:\n",
    "        lst1.append(strr1)\n",
    "        return glob\n",
    "            \n",
    "for i in range(len(human_values)):\n",
    "    for j in range(len(mouse_values)):\n",
    "        if func2(human_values[i],mouse_values[j],lst1)==True:\n",
    "            break\n",
    "\n",
    "print(lst1)\n",
    "print(len(lst1))\n",
    "'''\n",
    "fr1.close() #closing the file objects\n",
    "fr2.close() #closing the file objects\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 01: \n",
    "(a) How can we read multiple fasta entries from the above file and write them to a new file \n",
    "in the format as provided below?\n",
    "\n",
    "CYTC_MOUSE 140 MASPLRSLLFLLAVLAVAWAATPKQGPRMLGAPEEADANEEGVRRALDFAVSEYNKGSNDAYHSRAIQVVRARKQLVAGVNYFLDVEMGRTTCTKSQTNLTDCPFHDQPHLMRKALCSFQIYSVPWKGTHSLTKFSCKNA\n",
    "GHRL_MOUSE 117 MLSSGTICSLLLLSMLWMDMAMAGSSFLSPEHQKAQQRKESKKPPAKLQPRALEGWLHPEDRGQAEETEEELEIRFNAPFDVGIKLSGAQYQQHGRALGKFLQDILWEEVKEAPADK\n",
    "PCSK1_MOUSE 258 MAGSPLLCGPRAGGVGILVLLLLGLLRLPPTLSARPVKEPRSLSAASAPLVETSTPLRLRRAVPRGEAAGAVQELARALAHLLEAERQERARAEAQEAEDQQARVLAQLLRAWGSPRASDPPLAPDDDPDAPAAQLARALLRARLDPAALAAQLVPAPAAAPRPRPPVYDDGPTGPDVEDAGDETPDVDPELLRYLLGRILTGSSEPEAAPAPRRLRRSVDQDLGPEVPPENVLGALLRVKRLENPSPQAPARRLLPP\n",
    "\n",
    "\n",
    "\n",
    "(b) Define what is signal peptide and write some of its functions. Can you write a code to \n",
    "remove signal peptide from the start of each sequence? Note: the end position of the signal \n",
    "peptide is provided in the header of each sequence?\n",
    "\n",
    "\n",
    "(c) How can we read multiple files from a directory. You can take help from the internet.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CYTC_MOUSE', 'GHRL_MOUSE', 'PCSK1_MOUSE']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "'''\n",
    "Question 01: \n",
    "(a) How can we read multiple fasta entries from the above file and write them to a new file \n",
    "in the format as provided below?\n",
    "\n",
    "CYTC_MOUSE 140 MASPLRSLLFLLAVLAVAWAATPKQGPRMLGAPEEADANEEGVRRALDFAVSEYNKGSNDAYHSRAIQVVRARKQLVAGVNYFLDVEMGRTTCTKSQTNLTDCPFHDQPHLMRKALCSFQIYSVPWKGTHSLTKFSCKNA\n",
    "GHRL_MOUSE 117 MLSSGTICSLLLLSMLWMDMAMAGSSFLSPEHQKAQQRKESKKPPAKLQPRALEGWLHPEDRGQAEETEEELEIRFNAPFDVGIKLSGAQYQQHGRALGKFLQDILWEEVKEAPADK\n",
    "PCSK1_MOUSE 258 MAGSPLLCGPRAGGVGILVLLLLGLLRLPPTLSARPVKEPRSLSAASAPLVETSTPLRLRRAVPRGEAAGAVQELARALAHLLEAERQERARAEAQEAEDQQARVLAQLLRAWGSPRASDPPLAPDDDPDAPAAQLARALLRARLDPAALAAQLVPAPAAAPRPRPPVYDDGPTGPDVEDAGDETPDVDPELLRYLLGRILTGSSEPEAAPAPRRLRRSVDQDLGPEVPPENVLGALLRVKRLENPSPQAPARRLLPP\n",
    "\n",
    "\n",
    "\n",
    "(b) Define what is signal peptide and write some of its functions. Can you write a code to \n",
    "remove signal peptide from the start of each sequence? Note: the end position of the signal \n",
    "peptide is provided in the header of each sequence?\n",
    "\n",
    "\n",
    "(c) How can we read multiple files from a directory. You can take help from the internet.\n",
    "\n",
    "'''\n",
    "frr=open(\"f1f1.txt\",\"r\")\n",
    "line=frr.readline()\n",
    "ids=[]\n",
    "sequence=[]\n",
    "while(line):\n",
    "    if \">\" in line:\n",
    "        pattern=re.compile(\"\\w+\\_\\w+\")\n",
    "        match=pattern.findall(line)\n",
    "        match1=match[0]\n",
    "        ids.append(match1)\n",
    "    line=frr.readline()\n",
    "print(ids)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 01 (5 marks)\n",
    "Write a generic code to extract start and end positions of exons from the following \n",
    "string \"cds\". Print information as:\n",
    "    1) total number of exons\n",
    "    2) length of each exon\n",
    "    3) total number of introns\n",
    "    4) length of each intron\n",
    "\n",
    "cds = \"CDS\tjoin(100..221,345..600,771..908,4787..5452)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(12, 14), match='..'>\n",
      "<re.Match object; span=(21, 23), match='..'>\n",
      "<re.Match object; span=(30, 32), match='..'>\n",
      "<re.Match object; span=(40, 42), match='..'>\n",
      "total number of exons are: 4\n",
      "<re.Match object; span=(17, 18), match=','>\n",
      "<re.Match object; span=(26, 27), match=','>\n",
      "<re.Match object; span=(35, 36), match=','>\n",
      "total number of introns are: 3\n",
      "(100..221,345..600,771..908,4787..5452)\n",
      "(100,221,345,600,771,908,4787,5452)\n",
      "['', '100', '221', '345', '600', '771', '908', '4787', '5452', '']\n",
      "the length of exon is: 121\n",
      "the length of inton is: 124\n",
      "the length of exon is: 255\n",
      "the length of inton is: 171\n",
      "the length of exon is: 137\n",
      "the length of inton is: 3879\n",
      "the length of exon is: 665\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "cds=\"CDS\tjoin(100..221,345..600,771..908,4787..5452)\"\n",
    "a=0\n",
    "pattern=re.compile(r'\\.\\.')\n",
    "matches=pattern.finditer(cds)\n",
    "for match in matches:\n",
    "    a+=1\n",
    "    print(match)\n",
    "print('total number of exons are: '+str(a))\n",
    "b=0\n",
    "pattern=re.compile(r'\\,')\n",
    "matches=pattern.finditer(cds)\n",
    "for match in matches:\n",
    "    b+=1\n",
    "    print(match)\n",
    "print('total number of introns are: '+str(b))\n",
    "x=re.sub(r'[A-Z]|[a-z]|\\s','',cds)\n",
    "print(x)\n",
    "y=re.sub(r'\\.\\.',',',x)\n",
    "print(str(y))\n",
    "z=re.split('\\D',y)\n",
    "print(z)\n",
    "a=1\n",
    "b=2\n",
    "for i in range(7):\n",
    "    f=int(z[b])-int(z[a])\n",
    "    if(z[i]!=0 and z[i]!=9):\n",
    "        if(i%2==0):\n",
    "            print('the length of exon is: '+str(f))\n",
    "        elif(i%2!=0):\n",
    "            print('the length of inton is: '+str(f))\n",
    "        \n",
    "        a+=1\n",
    "        b+=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 02 (3 marks)\n",
    "Write a program that tells whether a particular sequence matches the site for \n",
    "the restriction enzyme EcoRI, or Bam HI, or Hind III. Print a message when the \n",
    "sequence is not matched to any of the three sites.\n",
    "\n",
    "Site for EcoR1: GAATTC\n",
    "Bam H1: GGATCC\n",
    "Hind III: AAGCTT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter a valid nucleotide sequence: TTCACCCCGCCAGGGTCACCCTATACGTTCATATACATGATGGGCCGTAGCTTCACTCCACGCACTATCTTAGTTATGCATCAAGGAGATCATGAATATTCAAATTCCAA\n",
      "site not present\n",
      "site not present\n",
      "site not present\n"
     ]
    }
   ],
   "source": [
    "Sequence=input('please enter a valid nucleotide sequence: ')\n",
    "Eco_R1='gaattc'\n",
    "Bam_H1='ggatcc'\n",
    "Hind_3='aagctt'\n",
    "count_ecor1=Sequence.count(Eco_R1)\n",
    "count_bamh1=Sequence.count(Bam_H1)\n",
    "count_hind3=Sequence.count(Hind_3)\n",
    "def Find_RS(R_Site, Seq, cou):\n",
    "    if cou > 0:\n",
    "        for match in re.finditer(R_Site, Seq):\n",
    "            print(R_Site+'is present')\n",
    "    else:\n",
    "        print('site not present')\n",
    "Find_RS(Eco_R1, Sequence, count_ecor1)\n",
    "Find_RS(Bam_H1, Sequence, count_bamh1)\n",
    "Find_RS(Hind_3, Sequence, count_hind3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question 04 (5 marks)\n",
    "Consider the following DNA string and write a program that prints the locations of \n",
    "all possible restriction sites for the restriction enzyme EcoRI, or Bam HI, \n",
    "or Hind III. \n",
    "\n",
    "dna = \"\"\"ttcacctatgaatggactgtccccaaagaagtaggacccactaatgcagatcctgtg\n",
    "tgtctagctaagatgtattattctgctgtggatcccactaaagatatattcactgggcttattgggccaa\n",
    "tgaaaatatgcaagaaaggaagtttacatgcaaatgggagacagaaagatgtagacaaggaattctattt\n",
    "gtttcctacagtatttgatgagaatgagagtttactcctggaagataatattagaatgtttacaactgca\n",
    "cctgatcaggtggataaggaagatgaagactttcaggaatctaataaaatgcactccatgaatggattca\n",
    "tgtatgggaatcagccgggtctcactatgtgcaaaggagattcggtcgtgtggtacttattcagcgccgg\n",
    "aaatgaggccgatgtacatggaatatacttttcaggaaacacatatctgtggagaggagaacggagagac\n",
    "acagcaaacctcttccctcaaacaagtcttacgctccacatgtggcctgacacagaggggacttttaatg\n",
    "ttgaatgccttacaactgatcattacacaggcggcatgaagcaaaaatatactgtgaaccaatgcaggcg\n",
    "gcagtctgaggattccaccttctacctgggagagaggacatactatatcgcagcagtggaggtggaatgg\n",
    "gattattccccacaaagggagtgggaaaaggagctgcatcatttacaagagcagaatgtttcaaatgcat\n",
    "ttttagataagggagagttttacataggctcaaagtacaagaaagttgtgtatcggcagtatactgatag\n",
    "cacattccgtgttccagtggagagaaaagctgaagaagaacatctgggaattctaggtccacaacttcat\n",
    "gcagatgttggagacaaagtcaaaattatctttaaaaacatggccacaaggccctactcaatacatgccc\n",
    "atggggtacaaacagagagttctacagttactccaacattaccaggtgaaactctcacttacgtatggaa\n",
    "aatcccagaaagatctggagctggaacagaggattctgcttgtattccatgggcttattattcaactgtg\n",
    "gatcaagttaaggacctctacagtggattaattggccccctgattgtttgtcgaagaccttacttgaaag\n",
    "tattcaatcccagaaggaagctggaatttgcccttctgtttctagtttttgatgagaatgaatcttggta\n",
    "cttagatgacaacatcaaaacatactctgatcaccccgagaaagtaaacaaagatgatgaggaattcata\n",
    "gaaagcaataaaatgcatgctattaatggaagaatgtttggaaacct\"\"\"\n",
    "\n",
    "\n",
    "Site for EcoR1: GAATTC\n",
    "Bam H1: GGATCC\n",
    "Hind III: AAGCTT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaattc site is present from indexes: 189-195\n",
      "gaattc site is present from indexes: 887-893\n",
      "gaattc site is present from indexes: 1327-1333\n",
      "ggatcc site is present from indexes: 88-94\n",
      "site not present\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "Sequence='''\n",
    "ttcacctatgaatggactgtccccaaagaagtaggacccactaatgcagatcctgtg\n",
    "tgtctagctaagatgtattattctgctgtggatcccactaaagatatattcactgggcttattgggccaa\n",
    "tgaaaatatgcaagaaaggaagtttacatgcaaatgggagacagaaagatgtagacaaggaattctattt\n",
    "gtttcctacagtatttgatgagaatgagagtttactcctggaagataatattagaatgtttacaactgca\n",
    "cctgatcaggtggataaggaagatgaagactttcaggaatctaataaaatgcactccatgaatggattca\n",
    "tgtatgggaatcagccgggtctcactatgtgcaaaggagattcggtcgtgtggtacttattcagcgccgg\n",
    "aaatgaggccgatgtacatggaatatacttttcaggaaacacatatctgtggagaggagaacggagagac\n",
    "acagcaaacctcttccctcaaacaagtcttacgctccacatgtggcctgacacagaggggacttttaatg\n",
    "ttgaatgccttacaactgatcattacacaggcggcatgaagcaaaaatatactgtgaaccaatgcaggcg\n",
    "gcagtctgaggattccaccttctacctgggagagaggacatactatatcgcagcagtggaggtggaatgg\n",
    "gattattccccacaaagggagtgggaaaaggagctgcatcatttacaagagcagaatgtttcaaatgcat\n",
    "ttttagataagggagagttttacataggctcaaagtacaagaaagttgtgtatcggcagtatactgatag\n",
    "cacattccgtgttccagtggagagaaaagctgaagaagaacatctgggaattctaggtccacaacttcat\n",
    "gcagatgttggagacaaagtcaaaattatctttaaaaacatggccacaaggccctactcaatacatgccc\n",
    "atggggtacaaacagagagttctacagttactccaacattaccaggtgaaactctcacttacgtatggaa\n",
    "aatcccagaaagatctggagctggaacagaggattctgcttgtattccatgggcttattattcaactgtg\n",
    "gatcaagttaaggacctctacagtggattaattggccccctgattgtttgtcgaagaccttacttgaaag\n",
    "tattcaatcccagaaggaagctggaatttgcccttctgtttctagtttttgatgagaatgaatcttggta\n",
    "cttagatgacaacatcaaaacatactctgatcaccccgagaaagtaaacaaagatgatgaggaattcata\n",
    "gaaagcaataaaatgcatgctattaatggaagaatgtttggaaacct\n",
    "'''\n",
    "Eco_R1='gaattc'\n",
    "Bam_H1='ggatcc'\n",
    "Hind_3='aagctt'\n",
    "count_ecor1=Sequence.count(Eco_R1)\n",
    "count_bamh1=Sequence.count(Bam_H1)\n",
    "count_hind3=Sequence.count(Hind_3)\n",
    "def Find_RS(R_Site, Seq, cou):\n",
    "    if cou > 0:\n",
    "        for match in re.finditer(R_Site, Seq):\n",
    "            print(R_Site+' site is present from indexes: '+str(match.start())+'-'+str(match.end()))\n",
    "    else:\n",
    "        print('site not present')\n",
    "Find_RS(Eco_R1, Sequence, count_ecor1)\n",
    "Find_RS(Bam_H1, Sequence, count_bamh1)\n",
    "Find_RS(Hind_3, Sequence, count_hind3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences found only in humans\n",
      "{'>INS_', '>IGF1c_', '>GON2_', '>IGF1b_', '>PPY2_', '>REL2_', '>MOTI_', '>MCHL2_', '>ADM5_', '>IGF1a_', '>MCHL1_', '>INSL4_'}\n",
      "sequences found only in mouse\n",
      "{'>HEPC2_', '>INS1_', '>IGF1_', '>INS2_'}\n",
      "is human a subset of mouse\n",
      "False\n",
      "is mouse a subset of humans\n",
      "False\n",
      "is human a superset of mouse\n",
      "False\n",
      "is mouse a superste of humans\n",
      "False\n",
      "sequences found in either mouse or humans but not in both\n",
      "{'>HEPC2_', '>INS1_', '>MCHL2_', '>ADM5_', '>REL2_', '>IGF1c_', '>IGF1b_', '>PPY2_', '>IGF1_', '>GON2_', '>MOTI_', '>INS2_', '>MCHL1_', '>IGF1a_', '>INSL4_', '>INS_'}\n",
      "all sequences found in mouse and humans excluding those whcih are a repitition\n",
      "{'', '>CRF_', '>ANFC_', '>OREX_', '>EDN3_', '>CCKN_', '>UCN1_', '>OSTN_', '>PTHY_', '>VEGFC_', '>NMU_', '>UCN3_', '>MCH_', '>IGF1c_', '>ANFB_', '>OX26_', '>NMB_', '>PCSK1_', '>TKNK_', '>IGF2_', '>KISS1_', '>CMGA_', '>GON2_', '>TIP39_', '>CALCB_', '>MOTI_', '>PDGFA_', '>VIP_', '>EDN2_', '>COLI_', '>GALP_', '>ANF_', '>ADM2_', '>PYY_', '>GRP_', '>PDGFB_', '>SMS_', '>UCN2_', '>SCG1_', '>GIP_', '>IGF1a_', '>PDYN_', '>INSL4_', '>INS_', '>SCG3_', '>CALCA1_', '>AUGN_', '>ADML_', '>VGF_', '>PRRP_', '>PDGFD_', '>SCG2_', '>GAST_', '>HEPC2_', '>RFRP_', '>INS1_', '>GALA_', '>APEL_', '>NEU2_', '>MCHL2_', '>ADM5_', '>TKN4_', '>SLIB_', '>PNOC_', '>NPS_', '>NPFF_', '>TOR2X_', '>UTS2_', '>INSL5_', '>REL2_', '>EDN1_', '>CORT_', '>IGF1b_', '>NEU1_', '>PPY2_', '>UTS2B_', '>IGF1_', '>TKN1_', '>IAPP_', '>PROK2_', '>NMS_', '>PENK_', '>GON1_', '>NUCB2_', '>NPY_', '>REL3_', '>CYTC_', '>SECR_', '>GLUC_', '>PTHR_', '>VEGFD_', '>GHRL_', '>CART_', '>CALCA_', '>NPB_', '>INS2_', '>NPW_', '>MCHL1_', '>NEUT_', '>REL1_', '>INSL3_', '>INSL6_', '>HEPC_', '>TRH_', '>PAHO_', '>SPXN_', '>RES18_', '>PACA_'}\n",
      "sequences commonly found in humans and mouse\n",
      "{'', '>CRF_', '>ANFC_', '>OREX_', '>EDN3_', '>CCKN_', '>UCN1_', '>OSTN_', '>VEGFC_', '>PTHY_', '>NMU_', '>UCN3_', '>MCH_', '>ANFB_', '>OX26_', '>NMB_', '>PCSK1_', '>TKNK_', '>IGF2_', '>KISS1_', '>CMGA_', '>TIP39_', '>CALCB_', '>PDGFA_', '>VIP_', '>EDN2_', '>COLI_', '>GALP_', '>ANF_', '>ADM2_', '>PYY_', '>GRP_', '>PDGFB_', '>SMS_', '>UCN2_', '>SCG1_', '>GIP_', '>PDYN_', '>SCG3_', '>CALCA1_', '>AUGN_', '>ADML_', '>VGF_', '>PRRP_', '>PDGFD_', '>SCG2_', '>GAST_', '>RFRP_', '>GALA_', '>APEL_', '>NEU2_', '>TKN4_', '>SLIB_', '>PNOC_', '>NPS_', '>NPFF_', '>TOR2X_', '>UTS2_', '>INSL5_', '>EDN1_', '>CORT_', '>NEU1_', '>UTS2B_', '>TKN1_', '>IAPP_', '>PROK2_', '>NMS_', '>PENK_', '>GON1_', '>NUCB2_', '>NPY_', '>REL3_', '>CYTC_', '>SECR_', '>GLUC_', '>PTHR_', '>VEGFD_', '>GHRL_', '>CART_', '>CALCA_', '>NPB_', '>NPW_', '>NEUT_', '>REL1_', '>INSL3_', '>INSL6_', '>HEPC_', '>TRH_', '>PAHO_', '>SPXN_', '>RES18_', '>PACA_'}\n"
     ]
    }
   ],
   "source": [
    "import re #importing re modeule for pattern recognition\n",
    "fr1=open(\"human.txt\",\"r\") \n",
    "fr2=open(\"mouse.txt\",\"r\") #opening mouse and human files\n",
    "line1=fr1.readline() #reading indivisual lines and storing them in line variables\n",
    "line2=fr2.readline()\n",
    "pat=re.compile(r\">\\w+\\_\") #pattern recognition using re.compile function \n",
    "m=set() \n",
    "h=set() #creating mouse and human sets to store sequence names for further operations\n",
    "while line1: #implementing while loops to read each line and perform suitable operations\n",
    "    match1=pat.findall(line1) #finding the line stating from \">\"\n",
    "    h.add(\"\".join(match1)) #adding the matched pattern in the human or mouse sets\n",
    "    line1=fr1.readline() #to read the next line\n",
    "while line2:\n",
    "    match2=pat.findall(line2)\n",
    "    m.add(\"\".join(match2))\n",
    "    line2=fr2.readline()\n",
    "\n",
    "print(\"sequences found only in humans\\n{}\".format(h-m)) #sequences found only in humans but not in mouse\n",
    "print(\"sequences found only in mouse\\n{}\".format(m-h)) #sequences foung only in mouse but not in humans\n",
    "print(\"is human a subset of mouse\\n{}\".format(h<m)) #is human a subset of mouse\n",
    "print(\"is mouse a subset of humans\\n{}\".format(m<h)) #is mouse a subset of human\n",
    "print(\"is human a superset of mouse\\n{}\".format(h>m)) #is human a superset of mouse\n",
    "print(\"is mouse a superste of humans\\n{}\".format(m>h)) #is mouse a superset of human\n",
    "print(\"sequences found in either mouse or humans but not in both\\n{}\".format(m^h)) #those sequences found in either mouse or human but bot in both\n",
    "print(\"all sequences found in mouse and humans excluding those whcih are a repitition\\n{}\".format(m|h)) #all sequences found in both mouse and humans excluding the repititive sequences\n",
    "print(\"sequences commonly found in humans and mouse\\n{}\".format(m&h)) #sequences found commonly in humans and mouse\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) Write regular expressions to extract LOCUS name and date from the following line:\n",
    "\n",
    "LOCUS       AB082923                2451 bp    mRNA    linear   PRI 01-APR-2003\n",
    "\n",
    "\n",
    "2) Extract CDS start and end from the following line:\n",
    "     CDS             64..1245\n",
    "\n",
    "3) write a code to remove spaces and numbers from the following sequence and merge all lines\n",
    "    to create a simple FASTA sequence. Extract start and stop codons based on CDS positions.\n",
    "    Can you predict exon boundaries based on splice donor and acceptor sequences.\n",
    "\n",
    "        1 cgtgctttcc acgacggtga cacgcttccc tggattggcc agactgcctt ccgggtcact\n",
    "       61 gccatggagg agccgcagtc agatcctagc gtcgagcccc ctctgagtca ggaaacattt\n",
    "      121 tcagacctat ggaaactact tcctgaaaac aacgttctgt cccccttgcc gtcccaagca\n",
    "      181 atggatgatt tgatgctgtc cccggacgat attgaacaat ggttcactga agacccaggt\n",
    "      241 ccagatgaag ctcccagaat gccagaggct gctccccgcg tggcccctgc accagcagct\n",
    "      301 cctacaccgg cggcccctgc accagccccc tcctggcccc tgtcatcttc tgtcccttcc\n",
    "      361 cagaaaacct accagggcag ctacggtttc cgtctgggct tcttgcattc tgggacagcc\n",
    "      421 aagtctgtga cttgcacgta ctcccctgcc ctcaacaaga tgttttgcca actggccaag\n",
    "      481 acctgccctg tgcagctgtg ggttgattcc acacccccgc ccggcacccg cgtccgcgcc\n",
    "      541 atggccatct acaagcagtc acagcacatg acggaggttg tgaggcgctg cccccaccat\n",
    "      601 gagcgctgct cagatagcga tggtctggcc cctcctcagc atcttatccg agtggaagga\n",
    "      661 aatttgcgtg tggagtattt ggatgacaga aacacttttc gacatagtgt ggtggtgccc\n",
    "      721 tatgagccgc ctgaggttgg ctctgactgt accaccatcc actacaacta catgtgtaac\n",
    "      781 agttcctgca tgggcggcat gaaccggagg cccatcctca ccatcatcac actggaagac\n",
    "      841 tccagtggta atctactggg acggaacagc tttgaggtgc atgtttgtgc ctgtcctggg\n",
    "      901 agagaccggc gcacagagga agagaatctc cgcaagaaag gggagcctca ccacgagctg\n",
    "      961 cccccaggga gcactaagcg agcactgtcc aacaacacca gctcctctcc ccagccaaag\n",
    "     1021 aagaaaccac tggatggaga atatttcacc cttcagatcc gtgggcgtga gcgcttcgag\n",
    "     1081 atgttccgag agctgaatga ggccttggaa ctcaaggatg cccaggctgg gaaggagcca\n",
    "     1141 ggggggagca gggctcactc cagccacctg aagtccaaaa agggtcagtc tacctcccgc\n",
    "     1201 cataaaaaac tcatgttcaa gacagaaggg cctgactcag actgacattc tccacttctt\n",
    "     1261 gttccccact gacagcctcc cacccccatc tctccctccc ctgccatttt gggttttggg\n",
    "     1321 tctttgaacc cttgcttgca ataggtgtgc gtcagaagca cccaggactt ccatttgctt\n",
    "     1381 tgtcccgggg ctccactgaa caagttggcc tgcactggtg ttttgttgtg gggaggagga\n",
    "     1441 tggggagtag gacataccag cttagatttt aaggttttta ctgtgaggga tgtttgggag\n",
    "     1501 atgtaagaaa tgttcttgca gttaagggtt agtttacaat cagccacatt ctaggtaggg\n",
    "     1561 gcccacttca ccgtactaac cagggaagct gtccctcact gttgaatttt ctctaacttc\n",
    "     1621 aaggcccata tctgtgaaat gctggcattt gcacctacct cacagagtgc attgtgaggg\n",
    "     1681 ttaatgaaat aatgtacatc tggccttgaa accacctttt attacatggg gtctagaact\n",
    "     1741 tgaccccctt gagggtgctt gttccctctc cctgttggtc ggtgggttgg tagtttctac\n",
    "     1801 agttgggcag ctggttaggt agagggagtt gtcaagtctc tgctggccca gccaaaccct\n",
    "     1861 gtctgacaac ctcttggtga accttagtac ctaaaaggaa atctcacccc atcccacacc\n",
    "     1921 ctggaggatt tcatctcttg tatatgatga tctggatcca ccaagacttg ttttatgctc\n",
    "     1981 agggtcaatt tcttttttct tttttttttt ttttttcttt ttctttgaga ctgggtctcg\n",
    "     2041 ctttgttgcc caggctggag tggagtggcg tgatcttggc ttactgcagc ctttgcctcc\n",
    "     2101 ccggctcgag cagtcctgcc tcagcctccg gagtagctgg gaccacaggt tcatgccacc\n",
    "     2161 atggccagcc aacttttgca tgttttgtag agatggggtc tcacagtgtt gcccaggctg\n",
    "     2221 gtctcaaact cctgggctca ggcgatccac ctgtctcagc ctcccagagt gctgggatta\n",
    "     2281 caattgtgag ccaccacgtc cagctggaag ggtcaacatc ttttacattc tgcaagcaca\n",
    "     2341 tctgcatttt caccccaccc ttcccctcct tctccctttt tatatcccat ttttatatcg\n",
    "     2401 atctcttatt ttacaataaa actttgctgc caaaaaaaaa aaaaaaaaaa a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cgtgctttccacgacggtgacacgcttccctggattggccagactgccttccgggtcactgccatggaggagccgcagtcagatcctagcgtcgagccccctctgagtcaggaaacattttcagacctatggaaactacttcctgaaaacaacgttctgtcccccttgccgtcccaagcaatggatgatttgatgctgtccccggacgatattgaacaatggttcactgaagacccaggtccagatgaagctcccagaatgccagaggctgctccccgcgtggcccctgcaccagcagctcctacaccggcggcccctgcaccagccccctcctggcccctgtcatcttctgtcccttcccagaaaacctaccagggcagctacggtttccgtctgggcttcttgcattctgggacagccaagtctgtgacttgcacgtactcccctgccctcaacaagatgttttgccaactggccaagacctgccctgtgcagctgtgggttgattccacacccccgcccggcacccgcgtccgcgccatggccatctacaagcagtcacagcacatgacggaggttgtgaggcgctgcccccaccatgagcgctgctcagatagcgatggtctggcccctcctcagcatcttatccgagtggaaggaaatttgcgtgtggagtatttggatgacagaaacacttttcgacatagtgtggtggtgccctatgagccgcctgaggttggctctgactgtaccaccatccactacaactacatgtgtaacagttcctgcatgggcggcatgaaccggaggcccatcctcaccatcatcacactggaagactccagtggtaatctactgggacggaacagctttgaggtgcatgtttgtgcctgtcctgggagagaccggcgcacagaggaagagaatctccgcaagaaaggggagcctcaccacgagctgcccccagggagcactaagcgagcactgtccaacaacaccagctcctctccccagccaaagaagaaaccactggatggagaatatttcacccttcagatccgtgggcgtgagcgcttcgagatgttccgagagctgaatgaggccttggaactcaaggatgcccaggctgggaaggagccaggggggagcagggctcactccagccacctgaagtccaaaaagggtcagtctacctcccgccataaaaaactcatgttcaagacagaagggcctgactcagactgacattctccacttcttgttccccactgacagcctcccacccccatctctccctcccctgccattttgggttttgggtctttgaacccttgcttgcaataggtgtgcgtcagaagcacccaggacttccatttgctttgtcccggggctccactgaacaagttggcctgcactggtgttttgttgtggggaggaggatggggagtaggacataccagcttagattttaaggtttttactgtgagggatgtttgggagatgtaagaaatgttcttgcagttaagggttagtttacaatcagccacattctaggtaggggcccacttcaccgtactaaccagggaagctgtccctcactgttgaattttctctaacttcaaggcccatatctgtgaaatgctggcatttgcacctacctcacagagtgcattgtgagggttaatgaaataatgtacatctggccttgaaaccaccttttattacatggggtctagaacttgacccccttgagggtgcttgttccctctccctgttggtcggtgggttggtagtttctacagttgggcagctggttaggtagagggagttgtcaagtctctgctggcccagccaaaccctgtctgacaacctcttggtgaaccttagtacctaaaaggaaatctcaccccatcccacaccctggaggatttcatctcttgtatatgatgatctggatccaccaagacttgttttatgctcagggtcaatttcttttttctttttttttttttttttctttttctttgagactgggtctcgctttgttgcccaggctggagtggagtggcgtgatcttggcttactgcagcctttgcctccccggctcgagcagtcctgcctcagcctccggagtagctgggaccacaggttcatgccaccatggccagccaacttttgcatgttttgtagagatggggtctcacagtgttgcccaggctggtctcaaactcctgggctcaggcgatccacctgtctcagcctcccagagtgctgggattacaattgtgagccaccacgtccagctggaagggtcaacatcttttacattctgcaagcacatctgcattttcaccccacccttcccctccttctccctttttatatcccatttttatatcgatctcttattttacaataaaactttgctgccaaaaaaaaaaaaaaaaaaaa\n",
      "{'', 'atgttcaagacagaagggcctgactcagactgacattctccacttcttgttccccactgacagcctcccacccccatctctccctcccctgccattttgggttttgggtctttgaacccttgcttgcaatag', 'atgttcaagacagaagggcctgactcagactgacattctccacttcttgttccccactga', 'atggccagccaacttttgcatgttttgtagagatggggtctcacagtgttgcccaggctggtctcaaactcctgggctcaggcgatccacctgtctcagcctcccagagtgctgggattacaattgtga', 'atggccagccaacttttgcatgttttgtag', 'atgaaataa', 'atgttcttgcagttaagggttagtttacaatcagccacattctag', 'atggggtctagaacttgacccccttgagggtgcttgttccctctccctgttggtcggtgggttggtagtttctacagttgggcagctggttaggtagagggagttgtcaagtctctgctggcccagccaaaccctgtctga', 'atgctcagggtcaatttcttttttctttttttttttttttttctttttctttgagactgggtctcgctttgttgcccaggctggagtggagtggcgtga', 'atgtaa', 'atggggtctagaacttgacccccttga', 'atgctggcatttgcacctacctcacagagtgcattgtga', 'atgttcaagacagaagggcctgactcagactga', 'atgctcagggtcaatttcttttttctttttttttttttttttctttttctttgagactgggtctcgctttgttgcccaggctggagtggagtggcgtgatcttggcttactgcagcctttgcctccccggctcgagcagtcctgcctcagcctccggagtag', 'atggggtctagaacttga', 'atgttcttgcagttaagggttagtttacaatcagccacattctaggtaggggcccacttcaccgtactaaccagggaagctgtccctcactgttga', 'atgctcagggtcaatttcttttttctttttttttttttttttctttttctttga', 'atggggtctagaacttgacccccttgagggtgcttgttccctctccctgttggtcggtgggttggtagtttctacagttgggcagctggttaggtagagggagttgtcaagtctctgctggcccagccaaaccctgtctgacaacctcttggtgaaccttagtacctaaaaggaaatctcaccccatcccacaccctggaggatttcatctcttgtatatga', 'atggggtctagaacttgacccccttgagggtgcttgttccctctccctgttggtcggtgggttggtagtttctacagttgggcagctggttaggtagagggagttgtcaagtctctgctggcccagccaaaccctgtctgacaacctcttggtgaaccttag', 'atggggtctagaacttgacccccttgagggtgcttgttccctctccctgttggtcggtgggttggtagtttctacagttgggcagctggttaggtagagggagttgtcaagtctctgctggcccagccaaaccctgtctgacaacctcttggtgaaccttagtacctaaaaggaaatctcaccccatcccacaccctggaggatttcatctcttgtatatgatga', 'atggggtctagaacttgacccccttgagggtgcttgttccctctccctgttggtcggtgggttggtagtttctacagttgggcagctggttag'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "frr=open('re_file.txt','r').read()\n",
    "frr=re.split(r'\\s',frr)\n",
    "file=[]\n",
    "for i in range(len(frr)):\n",
    "    if 'c' in frr[i] or 'a' in frr[i] or 't' in frr[i] or 'g' in frr[i]:\n",
    "        file.append(frr[i])\n",
    "file=\"\".join(file)\n",
    "print(file)\n",
    "codons=[]\n",
    "var1=0\n",
    "var2=3\n",
    "for i in range(len(file)//3):\n",
    "    codons.append(\"\".join(file[var1:var2]))\n",
    "    var1+=3\n",
    "    var2+=3\n",
    "gene=[]\n",
    "start=0\n",
    "stop=0\n",
    "for i in range(len(codons)):\n",
    "    if codons[i] == 'atg':\n",
    "        start=i\n",
    "    elif codons[i] == 'taa' or codons[i] == 'tga' or codons[i] == 'tag':\n",
    "        stop=i\n",
    "    if start != 0 and stop != 0:\n",
    "        gene.append(\"\".join(codons[start:stop+1]))\n",
    "print(set(gene))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locus name: AB082923\n",
      "date: 01-APR-2003\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "locus='LOCUS       AB082923                2451 bp    mRNA    linear   PRI 01-APR-2003'\n",
    "pat1=r\"\\w+\\d+\"\n",
    "pat2=r\"\\d+\\-\\w+\\-\\d+\"\n",
    "print(\"locus name: \"+re.findall(pat1,locus)[0])\n",
    "print(\"date: \"+re.findall(pat2,locus)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 64 end: 1245\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "cds='     CDS             64..1245'\n",
    "pat=r\"\\d+\"\n",
    "print(\"start: \"+re.findall(pat,cds)[0]+\" \"+\"end: \"+re.findall(pat,cds)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PENK_BOVIN.txt', 'PENK_HUMAN.txt', 'PENK_MOUSE.txt', 'PENK_RAT.txt']\n",
      "AC   P01211; Q2T9T4;\n",
      "\n",
      "DT   21-JUL-1986, integrated into UniProtKB/Swiss-Prot.\n",
      "\n",
      "DT   21-JUL-1986, sequence version 1.\n",
      "\n",
      "DT   04-MAR-2015, entry version 102.\n",
      "\n",
      "DE   RecName: Full=Proenkephalin-A;\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=Synenkephalin;\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=Met-enkephalin;\n",
      "\n",
      "DE     AltName: Full=Opioid growth factor;\n",
      "\n",
      "DE              Short=OGF;\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=PENK(111-130);\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=PENK(140-179);\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=Met-enkephalin-Arg-Gly-Leu;\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=Leu-enkephalin;\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=Enkelytin;\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=PENK(233-254);\n",
      "\n",
      "DE   Contains:\n",
      "\n",
      "DE     RecName: Full=Met-enkephalin-Arg-Phe;\n",
      "\n",
      "DE   Flags: Precursor;\n",
      "\n",
      "GN   Name=PENK;\n",
      "\n",
      "OS   Bos taurus (Bovine).\n",
      "\n",
      "OC   Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi;\n",
      "\n",
      "OC   Mammalia; Eutheria; Laurasiatheria; Cetartiodactyla; Ruminantia;\n",
      "\n",
      "OC   Pecora; Bovidae; Bovinae; Bos.\n",
      "\n",
      "OX   NCBI_TaxID=9913;\n",
      "\n",
      "RN   [1]\n",
      "\n",
      "RP   NUCLEOTIDE SEQUENCE [MRNA].\n",
      "\n",
      "RX   PubMed=6276759; DOI=10.1038/295202a0;\n",
      "\n",
      "RA   Noda M., Furutani Y., Takahashi H., Toyosato M., Hirose T.,\n",
      "\n",
      "RA   Inayama S., Nakanishi S., Numa S.;\n",
      "\n",
      "RT   \"Cloning and sequence analysis of cDNA for bovine adrenal\n",
      "\n",
      "RT   preproenkephalin.\";\n",
      "\n",
      "RL   Nature 295:202-206(1982).\n",
      "\n",
      "RN   [2]\n",
      "\n",
      "RP   NUCLEOTIDE SEQUENCE [LARGE SCALE MRNA].\n",
      "\n",
      "RC   STRAIN=Crossbred X Angus; TISSUE=Liver;\n",
      "\n",
      "RG   NIH - Mammalian Gene Collection (MGC) project;\n",
      "\n",
      "RL   Submitted (DEC-2005) to the EMBL/GenBank/DDBJ databases.\n",
      "\n",
      "RN   [3]\n",
      "\n",
      "RP   NUCLEOTIDE SEQUENCE [MRNA] OF 47-263.\n",
      "\n",
      "RX   PubMed=6173760; DOI=10.1038/295206a0;\n",
      "\n",
      "RA   Gubler U., Seeburg P., Hoffman B.J., Gage L.P., Udenfriend S.;\n",
      "\n",
      "RT   \"Molecular cloning establishes proenkephalin as precursor of\n",
      "\n",
      "RT   enkephalin-containing peptides.\";\n",
      "\n",
      "RL   Nature 295:206-208(1982).\n",
      "\n",
      "RN   [4]\n",
      "\n",
      "RP   NUCLEOTIDE SEQUENCE [MRNA] OF 211-229.\n",
      "\n",
      "RX   PubMed=6952189; DOI=10.1073/pnas.79.2.360;\n",
      "\n",
      "RA   Comb M., Herbert E., Crea R.;\n",
      "\n",
      "RT   \"Partial characterization of the mRNA that codes for enkephalins in\n",
      "\n",
      "RT   bovine adrenal medulla and human pheochromocytoma.\";\n",
      "\n",
      "RL   Proc. Natl. Acad. Sci. U.S.A. 79:360-364(1982).\n",
      "\n",
      "RN   [5]\n",
      "\n",
      "RP   PROTEIN SEQUENCE OF 233-261.\n",
      "\n",
      "RC   TISSUE=Chromaffin cell;\n",
      "\n",
      "RX   PubMed=8654396; DOI=10.1111/j.1432-1033.1996.t01-1-00516.x;\n",
      "\n",
      "RA   Goumon Y., Strub J.-M., Moniatte M., Nulans G., Poteur L., Hubert P.,\n",
      "\n",
      "RA   van Dorsselaer A., Aunis D., Metz-Boutigue M.-H.;\n",
      "\n",
      "RT   \"The C-terminal bisphosphorylated proenkephalin-A-(209-237)-peptide\n",
      "\n",
      "RT   from adrenal medullary chromaffin granules possesses antibacterial\n",
      "\n",
      "RT   activity.\";\n",
      "\n",
      "RL   Eur. J. Biochem. 235:516-525(1996).\n",
      "\n",
      "CC   -!- FUNCTION: Met- and Leu-enkephalins compete with and mimic the\n",
      "\n",
      "CC       effects of opiate drugs. They play a role in a number of\n",
      "\n",
      "CC       physiologic functions, including pain perception and responses to\n",
      "\n",
      "CC       stress. PENK(111-130) and PENK(233-254) increase glutamate release\n",
      "\n",
      "CC       in the striatum. PENK(111-130) decreases GABA concentration in the\n",
      "\n",
      "CC       striatum.\n",
      "\n",
      "CC   -!- FUNCTION: Enkelytin possesses antibacterial activity against Gram-\n",
      "\n",
      "CC       positive bacteria such as Micrococcus luteus and Bacillus\n",
      "\n",
      "CC       megaterium.\n",
      "\n",
      "CC   -!- SUBCELLULAR LOCATION: Secreted.\n",
      "\n",
      "CC   -!- PTM: The N-terminal domain contains 6 conserved cysteines thought\n",
      "\n",
      "CC       to be involved in disulfide bonding and/or processing.\n",
      "\n",
      "CC   -!- SIMILARITY: Belongs to the opioid neuropeptide precursor family.\n",
      "\n",
      "CC       {ECO:0000305}.\n",
      "\n",
      "CC   -----------------------------------------------------------------------\n",
      "\n",
      "CC   Copyrighted by the UniProt Consortium, see http://www.uniprot.org/terms\n",
      "\n",
      "CC   Distributed under the Creative Commons Attribution-NoDerivs License\n",
      "\n",
      "CC   -----------------------------------------------------------------------\n",
      "\n",
      "DR   EMBL; V00109; CAA23443.1; -; mRNA.\n",
      "\n",
      "DR   EMBL; BC111279; AAI11280.1; -; mRNA.\n",
      "\n",
      "DR   EMBL; V00108; CAA23442.1; -; mRNA.\n",
      "\n",
      "DR   EMBL; J00012; AAA30673.1; -; mRNA.\n",
      "\n",
      "DR   PIR; A93272; EQBOA.\n",
      "\n",
      "DR   RefSeq; NP_776566.1; NM_174141.2.\n",
      "\n",
      "DR   UniGene; Bt.166; -.\n",
      "\n",
      "DR   STRING; 9913.ENSBTAP00000006478; -.\n",
      "\n",
      "DR   PRIDE; P01211; -.\n",
      "\n",
      "DR   Ensembl; ENSBTAT00000006478; ENSBTAP00000006478; ENSBTAG00000004924.\n",
      "\n",
      "DR   GeneID; 281387; -.\n",
      "\n",
      "DR   KEGG; bta:281387; -.\n",
      "\n",
      "DR   CTD; 5179; -.\n",
      "\n",
      "DR   eggNOG; NOG40630; -.\n",
      "\n",
      "DR   GeneTree; ENSGT00530000063761; -.\n",
      "\n",
      "DR   HOGENOM; HOG000013003; -.\n",
      "\n",
      "DR   HOVERGEN; HBG000063; -.\n",
      "\n",
      "DR   InParanoid; P01211; -.\n",
      "\n",
      "DR   KO; K18832; -.\n",
      "\n",
      "DR   OMA; FMKKMDE; -.\n",
      "\n",
      "DR   OrthoDB; EOG75TMCR; -.\n",
      "\n",
      "DR   TreeFam; TF332620; -.\n",
      "\n",
      "DR   Reactome; REACT_210568; G alpha (i) signalling events.\n",
      "\n",
      "DR   Reactome; REACT_219025; Peptide ligand-binding receptors.\n",
      "\n",
      "DR   NextBio; 20805387; -.\n",
      "\n",
      "DR   Proteomes; UP000009136; Chromosome 14.\n",
      "\n",
      "DR   GO; GO:0005576; C:extracellular region; IEA:UniProtKB-SubCell.\n",
      "\n",
      "DR   GO; GO:0002118; P:aggressive behavior; IEA:Ensembl.\n",
      "\n",
      "DR   GO; GO:0001662; P:behavioral fear response; IEA:Ensembl.\n",
      "\n",
      "DR   GO; GO:0042742; P:defense response to bacterium; IEA:UniProtKB-KW.\n",
      "\n",
      "DR   GO; GO:0007626; P:locomotory behavior; IEA:Ensembl.\n",
      "\n",
      "DR   GO; GO:0007218; P:neuropeptide signaling pathway; IEA:UniProtKB-KW.\n",
      "\n",
      "DR   GO; GO:0019233; P:sensory perception of pain; IEA:Ensembl.\n",
      "\n",
      "DR   GO; GO:0001964; P:startle response; IEA:Ensembl.\n",
      "\n",
      "DR   InterPro; IPR006024; Opioid_neupept.\n",
      "\n",
      "DR   InterPro; IPR000703; Proenkphlin_A.\n",
      "\n",
      "DR   PANTHER; PTHR11438; PTHR11438; 1.\n",
      "\n",
      "DR   PANTHER; PTHR11438:SF3; PTHR11438:SF3; 1.\n",
      "\n",
      "DR   Pfam; PF01160; Opiods_neuropep; 1.\n",
      "\n",
      "DR   PRINTS; PR01028; OPIOIDPRCRSR.\n",
      "\n",
      "DR   PRINTS; PR01029; PENKAPRCRSR.\n",
      "\n",
      "DR   PROSITE; PS01252; OPIOIDS_PRECURSOR; 1.\n",
      "\n",
      "PE   1: Evidence at protein level;\n",
      "\n",
      "KW   Antibiotic; Antimicrobial; Cleavage on pair of basic residues;\n",
      "\n",
      "KW   Complete proteome; Direct protein sequencing; Disulfide bond;\n",
      "\n",
      "KW   Endorphin; Neuropeptide; Opioid peptide; Reference proteome; Secreted;\n",
      "\n",
      "KW   Signal.\n",
      "\n",
      "FT   SIGNAL        1     24       {ECO:0000255}.\n",
      "\n",
      "FT   PEPTIDE      25     94       Synenkephalin.\n",
      "\n",
      "FT                                /FTId=PRO_0000008206.\n",
      "\n",
      "FT   PEPTIDE      97    101       Met-enkephalin.\n",
      "\n",
      "FT                                /FTId=PRO_0000008207.\n",
      "\n",
      "FT   PEPTIDE     104    108       Met-enkephalin.\n",
      "\n",
      "FT                                /FTId=PRO_0000008208.\n",
      "\n",
      "FT   PEPTIDE     111    130       PENK(111-130). {ECO:0000250}.\n",
      "\n",
      "FT                                /FTId=PRO_0000377682.\n",
      "\n",
      "FT   PEPTIDE     133    137       Met-enkephalin.\n",
      "\n",
      "FT                                /FTId=PRO_0000008210.\n",
      "\n",
      "FT   PEPTIDE     140    179       PENK(140-179). {ECO:0000250}.\n",
      "\n",
      "FT                                /FTId=PRO_0000377683.\n",
      "\n",
      "FT   PEPTIDE     182    189       Met-enkephalin-Arg-Gly-Leu.\n",
      "\n",
      "FT                                /FTId=PRO_0000008212.\n",
      "\n",
      "FT   PROPEP      192    203\n",
      "\n",
      "FT                                /FTId=PRO_0000008213.\n",
      "\n",
      "FT   PEPTIDE     206    210       Met-enkephalin.\n",
      "\n",
      "FT                                /FTId=PRO_0000008214.\n",
      "\n",
      "FT   PROPEP      213    223\n",
      "\n",
      "FT                                /FTId=PRO_0000008215.\n",
      "\n",
      "FT   PEPTIDE     226    230       Leu-enkephalin.\n",
      "\n",
      "FT                                /FTId=PRO_0000008216.\n",
      "\n",
      "FT   PEPTIDE     233    261       Enkelytin.\n",
      "\n",
      "FT                                /FTId=PRO_0000008217.\n",
      "\n",
      "FT   PEPTIDE     233    254       PENK(233-254). {ECO:0000250}.\n",
      "\n",
      "FT                                /FTId=PRO_0000377684.\n",
      "\n",
      "FT   PEPTIDE     257    263       Met-enkephalin-Arg-Phe.\n",
      "\n",
      "FT                                /FTId=PRO_0000008218.\n",
      "\n",
      "FT   DISULFID     26     48       {ECO:0000250}.\n",
      "\n",
      "FT   DISULFID     30     52       {ECO:0000250}.\n",
      "\n",
      "FT   DISULFID     33     65       {ECO:0000250}.\n",
      "\n",
      "SQ   SEQUENCE   263 AA;  29788 MW;  0E400338A228B0D8 CRC64;\n",
      "\n",
      "     MARFLGLCTW LLALGPGLLA TVRAECSQDC ATCSYRLARP TDLNPLACTL ECEGKLPSLK\n",
      "\n",
      "     TWETCKELLQ LTKLELPPDA TSALSKQEES HLLAKKYGGF MKRYGGFMKK MDELYPLEVE\n",
      "\n",
      "     EEANGGEVLG KRYGGFMKKD AEEDDGLGNS SNLLKELLGA GDQREGSLHQ EGSDAEDVSK\n",
      "\n",
      "     RYGGFMRGLK RSPHLEDETK ELQKRYGGFM RRVGRPEWWM DYQKRYGGFL KRFAEPLPSE\n",
      "\n",
      "     EEGESYSKEV PEMEKRYGGF MRF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob #importing glob function that will find the pattern present in a specific directory and then fing the files\n",
    "files=[] #file names will be stored in this list\n",
    "for filename in glob.glob('PENK_*'): #the pattern is PENK_* all file starting with PENK_ will be returned\n",
    "    #other patterns can be *txt to find all text files\n",
    "    #*fasta to fing all fasta files\n",
    "    files.append(filename) #appending filenames in the list\n",
    "print(files) \n",
    "\n",
    "fr=open(files[0],'r') #opening the first file in reading mode\n",
    "line=fr.readline() #reading line by line\n",
    "for line in fr:\n",
    "    print(line)\n",
    "\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PENK_BOVIN.txt', 'PENK_HUMAN.txt', 'PENK_MOUSE.txt', 'PENK_RAT.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files=glob.glob('PENK_*')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB SESSIONALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'AT', 'AC', 'AG', 'TA', 'TT', 'TC', 'TG', 'CA', 'CT', 'CC', 'CG', 'GA', 'GT', 'GC', 'GG']\n",
      "AC\n",
      "TA\n",
      "CA\n",
      "['ACCAGA', 'CCAGAT', 'CAGATC', 'AGATCA', 'GATCAA', 'ATCAAC', 'TCAACG', 'CAACGC', 'AACGCC', 'ACGCCG', 'CGCCGA', 'GCCGAG', 'CCGAGA', 'CGAGAT', 'GAGATC', 'AGATCC', 'GATCCG', 'ATCCGG', 'TCCGGC', 'CCGGCA', 'CGGCAC', 'GGCACA', 'GCACAT', 'CACATG', 'ACATGA', 'CATGAA', 'ATGAAG', 'TGAAGG']\n",
      "[5, 5, 3, 6, 4, 5, 5, 3, 4, 4, 3, 4, 5, 5, 4, 6, 3, 3, 5, 5, 4, 5, 5, 1, 6, 4, 5, 5]\n",
      "23\n",
      "the most number of matches are with: CACATG and the score is: 1\n"
     ]
    }
   ],
   "source": [
    "a=['A','T','C','G']\n",
    "b=['A','T','C','G']\n",
    "d=[]\n",
    "seq1,seq2,seq3,seq4='GATTACA','TAGACCA','ATACA','CTACATGC'\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        d.append(a[i]+b[j])\n",
    "print(d)\n",
    "for i in range(len(d)):\n",
    "    if d[i] in seq1 and d[i] in seq2 and d[i] in seq3 and d[i] in seq4:\n",
    "        print(d[i])\n",
    "\n",
    "\n",
    "\n",
    "sequence='ACCAGATCAACGCCGAGATCCGGCACATGAAGG'\n",
    "consensus=list('CACCTG')\n",
    "\n",
    "length=len(sequence)-6+1\n",
    "sliding=[]\n",
    "score=[]\n",
    "for i in range(length):\n",
    "    sliding.append(sequence[i:i+6])\n",
    "print(sliding)\n",
    "for i in range(length):\n",
    "    mismatch=0\n",
    "    for j in range(6):\n",
    "        sliding1=list(sliding[i])\n",
    "        if consensus[j]!=sliding1[j]:\n",
    "            mismatch+=1\n",
    "    score.append(mismatch)\n",
    "print(score)\n",
    "a=0\n",
    "for i in range(len(score)):\n",
    "    if score[i]==min(score):\n",
    "        a=i\n",
    "        print(a)\n",
    "    \n",
    "\n",
    "print('the most number of matches are with: '+sliding[a]+' and the score is: '+str(min(score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTATC\n",
      "TTGTT\n"
     ]
    }
   ],
   "source": [
    "enzymes1=[\"CTATC\",\"GGATCC\",\"AAWTGC\",\"TTGTT\",\"GGANNNTCC\"]\n",
    "def func1(str1):\n",
    "    for base in str1:\n",
    "        if base != \"A\" or base != \"C\" or base != \"T\" or base != \"G\":\n",
    "            break\n",
    "    if str1 == str1[::-1]:\n",
    "        return True\n",
    "for i in range(len(enzymes1)):\n",
    "    if func1(enzymes1[i]):\n",
    "        print(enzymes1[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASGVALPLAGVFSL\n",
      "AWAGLGSPLS\n",
      "SLALADDAAF\n",
      "LLAALE\n",
      "APG\n",
      "WLDSYMQ\n",
      "LLLLDAP\n"
     ]
    }
   ],
   "source": [
    "protein=\"ASGVALPLAGVFSLRKAPGRAWAGLGSPLSRRSLALADDAAFREERAGRLLAALERRRWLDSYMQKLLLLDAP\"\n",
    "lst=protein.split(\"R\")\n",
    "for i in lst:\n",
    "    if \"K\" in i:\n",
    "        lst.extend(i.split(\"K\"))\n",
    "        lst.remove(i)\n",
    "for i in lst:\n",
    "    if len(i) >= 3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-a8072084d57e>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-a8072084d57e>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    for i in range(len(file1):\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "files=glob.glob(\"Files/*_*.txt\")\n",
    "print(files)\n",
    "def func1(file):\n",
    "    file1=open(file,'r').read().split('\\n')\n",
    "    print(file1)\n",
    "    lst_file1=[]\n",
    "    id=0\n",
    "    sq=0\n",
    "    pat1=r'\\w+\\_\\w+ | \\w\\d\\w+\\_\\w+'\n",
    "    for i in range(len(file1):\n",
    "        if 'S' in list(file1[i]) and 'Q' in list(file1[i]):\n",
    "            sq=i+1\n",
    "    lst_file1.append(\"\".join(re.findall(pat1,file1[id])))\n",
    "    lst_file1.append(\"\".join(file1[sq:]))\n",
    "    return lst_file1\n",
    "print(func1(files[0]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
